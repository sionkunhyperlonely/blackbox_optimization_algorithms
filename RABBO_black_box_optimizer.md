# RABBO: Region-wise Adaptive Bandit Black-box Optimizer

**RABBO (Region-wise Adaptive Bandit Black-box Optimizer)** は、  
ブラックボックス関数に対する「完全ブラックボックス」で「実用的」な最適化アルゴリズムの一案です。

> 既存手法との完全な独立性を数学的に保証するものではありませんが、  
> 標準的な BO / CMA-ES / PSO / Hyperband などとは明確に異なる構造を持つように設計しています。

---

## 1. 問題設定

目的関数：

\[
\min_{x \in \mathcal{X}} f(x)
\]

- \(f\) は勾配も構造も不明なブラックボックス。
- \(\mathcal{X} \subset \mathbb{R}^d\) はボックス制約付き領域（例：\([0,1]^d\)）。
- 評価は高コスト（秒〜分オーダー）で、ノイズを含む可能性がある。
- 勾配は利用できない・推定したくない。
- 並列評価（バッチ評価）が可能だと望ましい。

典型的な応用：
- ハイパーパラメータ最適化
- 実験条件の最適化
- シミュレータを用いた設計最適化 など

---

## 2. コアアイデア

RABBO は次の 3 要素を組み合わせたアルゴリズムです。

1. **領域分割（Region）**
   - 探索空間を動的に「領域」に分割し、各領域を 1 つの「腕（arm）」とみなす。

2. **各領域でのローカル探索（Local Search）**
   - 各領域内で、小規模データのみを利用した「軽量サロゲート + 信頼領域探索」を行う。
   - 大域的な GP を全空間に張る必要がなく、高次元・多データ設定でも現実的。

3. **マルチアームドバンディットによる資源配分（Bandit Control）**
   - 「どの領域にどれだけ評価回数を割り当てるか」を UCB 風のバンディットスコアで決める。
   - 領域ごとの改善度と試行回数を基に、探索と活用のバランスを自動的に調整。

直感的には：

> 「空間を複数の領域に切り、それぞれで小さな BO/局所探索を回し、  
>  どの領域に計算資源を投下するかをバンディットで決める」

という構造です。

---

## 3. データ構造

### 3.1 評価履歴

- 評価済みデータ集合

\[
\mathcal{D} = \{(x_i, y_i)\}_{i=1}^N
\]

### 3.2 領域（Region）

各領域 \(r\) は次の情報を持ちます。

- 領域の範囲（ボックス）  
  - \([l_r, u_r] \subset \mathcal{X}\)
- その領域内の評価点のインデックス集合  
  - \(I_r \subset \{1,\dots,N\}\)
- 統計量
  - \(n_r = |I_r|\)：その領域での評価回数
  - \(b_r = \min_{i \in I_r} y_i\)：その領域での最良値
  - \(g_r\)：領域内の**累積改善量**（後述）
  - \(t_r\)：領域が生成されてからのステップ数（age）
- バンディットスコア \(S_r\)

領域集合を \(\mathcal{R}\) と表す。

---

## 4. アルゴリズム概要

### 4.1 初期化

1. ラテン超方格（LHS）などで \(N_{\text{init}}\) 点を一様サンプリング。
2. それらを評価して \(\mathcal{D}\) を作成。
3. 初期領域として「全空間をカバーする 1 つの領域」 \(r_0\) を作る。
   - \(I_{r_0} = \{1,\dots,N_{\text{init}}\}\)
   - \(b_{r_0}, g_{r_0}, n_{r_0}, t_{r_0}\) を設定。

### 4.2 反復処理（バッチサイズ = B）

総評価予算を使い切るまで以下を繰り返す。

1. **バンディットスコアの更新**
2. **スコアに基づき領域を選択し、各領域内で候補点を生成**
3. **候補点を実際に評価し、\(\mathcal{D}\) および各領域の統計量を更新**
4. **領域の分割（split）と剪定（prune）**

---

## 5. ステップ詳細

### 5.1 バンディットスコアの更新

総評価回数を \(T = N\) とする。

**(a) 改善ベースの報酬**

- 領域 \(r\) における直近の評価を見て、
  以前の最良値 \(b_r^{\text{old}}\) から現在の最良値 \(b_r^{\text{new}}\) への改善量を

  \[
  \Delta_r = \max(0, b_r^{\text{old}} - b_r^{\text{new}})
  \]

  と定義する。

- 問題スケールで適宜正規化したうえで、これを「短期報酬」として累積改善量

  \[
  g_r \leftarrow g_r + \Delta_r
  \]

  を更新する。

**(b) UCB 風スコア**

- 改善の平均値（1 評価あたり）：

  \[
  \text{mean\_gain}_r =
  \begin{cases}
    g_r / n_r & (n_r > 0) \\
    +\infty & (n_r = 0)
  \end{cases}
  \]

- UCB 風のバンディットスコア：

  \[
  S_r = \text{mean\_gain}_r
        + c \sqrt{\frac{\log(T+1)}{n_r + 1}}
        - \lambda_{\text{age}} \cdot \text{stale}(t_r)
  \]

  - \(c > 0\)：探索度合い（UCB の係数）
  - \(\text{stale}(t_r)\)：改善のないまま古くなった領域へのペナルティ項  
    （例えば、一定ステップ改善がなければ単調増加する関数）

これにより、「改善が大きい＆試行回数が少ない領域」が高スコアとなり、  
探索と活用をバランスよく行える。

---

### 5.2 領域選択と候補点生成

#### (1) 領域選択

- 全領域の \(S_r\) を計算し、スコアの大きい順にソート。
- バッチサイズ \(B\) に合わせて、スコアに応じた確率や重みで
  領域を（重複を許して）選択する。

例：
- B = 16、領域数 = 4 の場合  
  スコアに応じた重み付きサンプリングなどで  
  \([r_1, r_1, r_1, r_2, r_2, r_2, r_3, \dots]\) のように選ぶ。

#### (2) 各領域内のローカル探索（Local proposal）

領域 \(r\) で 1 点の候補 \(x\) を生成する。

- 領域内評価点数 \(n_r\) が少ない場合（例：\(n_r < n_{\min}\)）：
  - **カバレッジ重視サンプリング**
    - 領域内で一様に \(M\) 点サンプリング。
    - 既存点からの最小距離 \(d(x, \text{既存点})\) を最大にする点を選ぶ（max-min サンプリング）。

- \(n_r\) が十分大きい場合：
  - **軽量サロゲート + 信頼領域**

    1. 領域内の評価点 \(I_r\) のうち、近傍 & 最近のものを選び、小さな局所モデルを構築。
       - モデル例：
         - 局所線形回帰
         - 局所二次回帰
         - RBF、ランダムフォレストなど
       - 高次元の場合は主成分分析などで局所的な次元削減を行ってもよい。

    2. 領域内最良点 \(x_r^*\) を中心とする信頼領域（trust region）を定義：

       \[
       \mathcal{T}_r = \{ x \in [l_r,u_r] : \|x - x_r^*\| \le \rho_r \}
       \]

       - \(\rho_r\) は「局所探索の半径」。
       - 改善が続く場合は少しずつ拡大し、停滞する場合は縮小するルールを設定する。

    3. サロゲート上でシンプルな獲得関数を最適化：
       - 例：「予測値 + 多様性ボーナス」

         \[
         A(x) = -\hat{f}_r(x) + \beta \cdot d(x, \text{既存点})
         \]

       - 勾配不要。信頼領域内でランダムサンプリングを多数行い、
         \(A(x)\) が最大の点を選ぶだけでも実用上は十分。

---

### 5.3 評価と統計更新

提案されたバッチ \(\{x^{(1)}, \dots, x^{(B)}\}\) をブラックボックス関数 \(f\) に入力し、  
得られた値 \(y^{(j)}\) を受け取る。

- それぞれを \(\mathcal{D}\) に追加。
- 各点が属する領域 \(r\) を判定し、インデックスを \(I_r\) に追加。
- 各領域について:
  - \(n_r\) を更新。
  - \(b_r\) を更新。
  - 改善があれば \(\Delta_r\) を計算し、\(g_r\) に加算。
  - \(t_r\) をインクリメント。
- グローバルベスト \((x^*, y^*)\) も更新。

---

### 5.4 領域の分割と剪定（Split & Prune）

一定ステップごとに以下の操作を行う。

#### (1) 分割（Split）

領域 \(r\) が以下を満たす場合、2 つの子領域に分割する。

- 評価点数が十分多い （例：\(n_r \ge n_{\text{split}}\)）
- 領域のサイズがまだ大きい
- 領域内の関数値にばらつきがある（分散などで判定）

分割方法の例：

- 分割方向：
  - 目的関数値の分散が最大の次元。
  - あるいは特徴量変換後の主成分方向。

- 分割位置：
  - 単純にその次元の中央。
  - または最良点の位置を境界にする。

分割後：

- 子領域 \(r_1, r_2\) それぞれの \(I_{r_i}\) を再計算。
- \(b_{r_i}, g_{r_i}, n_{r_i}, t_{r_i}\) を親から引き継ぎつつ再評価。
- 親領域は削除。

#### (2) 剪定（Prune）

- バンディットスコア \(S_r\) が、グローバルベスト領域のスコアより大きく劣る領域を一定割合で削除または休止させる。
- これにより、探索資源を有望な領域に集中させる。

---

## 6. 擬似コード（高レベル）

```python
def RABBO(f, bounds, budget, B=8):
    D = []  # (x, y) pairs
    R = []  # regions

    # --- init ---
    X_init = latin_hypercube(bounds, N_init)
    for x in X_init:
        y = f(x)
        D.append((x, y))
    root_region = Region(bounds, indices=range(len(D)))
    R.append(root_region)

    while eval_count(D) < budget:
        T = eval_count(D)

        # 1. update bandit scores
        for r in R:
            r.update_stats(D)      # n_r, b_r, g_r, etc.
            r.score = compute_bandit_score(r, T)

        # 2. select regions for this batch
        selected_regions = select_regions_by_score(R, B)

        # 3. propose candidates
        X_new = []
        for r in selected_regions:
            x_new = propose_in_region(r, D, bounds)
            X_new.append((x_new, r))

        # 4. evaluate batch
        for x_new, r in X_new:
            y_new = f(x_new)
            idx = len(D)
            D.append((x_new, y_new))
            r.add_index(idx)

        # 5. optional: split & prune
        R = split_and_prune_regions(R, D)

    # return best found
    return argmin(D)
```

この擬似コードでは、細部（`Region` クラスの定義、`compute_bandit_score`、`propose_in_region` など）は省略していますが、  
RABBO の全体フローはこのようになります。

---

## 7. 実用面での特徴

1. **高次元・多データへのスケール**
   - 大域的な GP を使わず、「各領域での小さな局所モデル」のみを使うため、
     評価点数が増えても計算量が爆発しにくい。
   - 局所的な次元削減を併用すれば、30〜100 次元程度でも実用的に動作しうる。

2. **並列評価との相性が良い**
   - バッチサイズ \(B\) に合わせて、スコアに応じて複数領域から候補点を出すだけなので、
     そのまま分散計算環境で並列評価が可能。

3. **ノイズに対して頑健**
   - バンディットの報酬を「改善量」で定義することで、ノイズがあっても統計的には収束しやすい。
   - 必要に応じて、同一点を複数回評価して平均を取るポリシーを各領域ごとに導入可能。

4. **実装コストが比較的低い**
   - サロゲートを「局所線形回帰 + ランダム探索」程度に抑えれば、
     汎用的な数値計算ライブラリのみで実装できる。

---

## 8. 既存手法との違い（概要）

- **標準的な BO（単一 GP + EI/UCB）**
  - 通常は「1 つの GP モデルで全空間を管理」する。
  - RABBO は「多数の局所モデル + バンディット制御」で構成され、
    高次元・多データ設定でのスケーラビリティを重視している。

- **CMA-ES などの進化戦略**
  - 1 つ（または少数）の集団が全空間をカバーする。
  - RABBO は「複数領域での並列ローカル探索」をバンディットで制御する点が異なる。

- **Hyperband / Successive Halving 系**
  - 「設定 × 予算」の割り当て問題をバンディット的に解くが、
    連続空間の幾何構造はあまり利用しない。
  - RABBO は空間を明示的に領域分割し、その幾何構造を活用する。

- **TuRBO / Trust-region BO 系**
  - 複数の信頼領域を管理するという点で類似するが、
  - RABBO は「領域 = バンディットの腕」として扱い、
    スコアに基づく資源配分・領域分割・剪定を導入している。

---

## 9. 拡張案

### 9.1 離散・カテゴリカル変数

- ボックス領域の代わりに、「組合せパターン集合のクラスタ」を領域とみなす。
- 各クラスタ内で局所的な近傍探索（ビットフリップ、隣接カテゴリへの変更など）を行う。

### 9.2 制約付き最適化

制約付き問題：

\[
\min f(x) \quad \text{s.t.} \quad g_j(x) \le 0, \; j=1,\dots,m
\]

- 各領域に「可行率（可行点の割合）」を統計量として持たせる。
- バンディットスコアに可行率を組み込んで、可行領域を優先的に探索。
- サロゲートで制約違反の確率を推定し、獲得関数にペナルティを付与することも可能。

---

## 10. 実装の出発点

Python でのプロトタイプ実装を考える場合、まずは次のような簡略版から始めるとよいでしょう。

1. 領域の分割は「常に最長辺で 2 分割」。
2. サロゲートは「領域内の最近 20 点に対する線形回帰」。
3. 信頼領域は「領域内の L2 球」（半径は経験則で決める）。
4. 候補点は「信頼領域内ランダムサンプリング 100 点 → 予測値最小の点」。

この簡略版でも、ランダム探索やシンプルな進化戦略に対して  
有意な改善が得られるかを実験的に確認しながら、  
モデルの高機能化（非線形サロゲートや高度な分割戦略など）を進められます。
