# LENS-BO: Local Ensemble Neighborhood Search for Black-box Optimization

## 概要

**LENS-BO**（Local Ensemble Neighborhood Search for Black-box Optimization）は、  
ブラックボックス関数の最適化のために設計された、新しい実用的アルゴリズム案である。

主な特徴：

- 高価なブラックボックス関数 \( f(x) \) の最小化（最大化も可）を対象とする。
- 低〜中次元（例：5〜50 次元程度）を想定。
- ノイズあり・不連続・多峰性の関数にもある程度ロバスト。
- ガウス過程ベイズ最適化より軽量な **局所サロゲートモデル + 探索ポリシー** を採用。
- 複数の「局所リージョン（トラストリージョン）」を並行して探索し、
  それぞれに対してアンサンブルサロゲートを構築する。

アイデアの核となる点：

1. **空間全体を一度にモデル化しない**  
   → 毎回「有望そうな局所近傍」のみを対象に軽量な回帰モデルを構築する。

2. **局所サロゲートのアンサンブル**  
   → ランダム特徴量やランダムサブサンプリングで複数の異なる近似モデルを作り、  
   それらから「平均」と「不確実性（分散）」を推定する。

3. **局所トラストリージョン + 不確実性駆動探索**  
   → ベイズ最適化の獲得関数に着想を得つつ、
     「グローバル GP」ではなく「局所線形／ランダム特徴回帰」を用いる。

4. **複数局所領域を並行して育てる**  
   → 現在のベストの周りだけではなく、他の有望そうな谷も並行して追跡する。

---

## 問題設定

最小化問題：

\[
\min_{x \in \Omega \subset \mathbb{R}^d} f(x)
\]

- \( f \) はブラックボックス関数（解析形不明・微分不可でよい）。
- ノイズありの評価 \( y = f(x) + \epsilon \) も許容する。
- 評価コストが高い（シミュレーション・実験など）ため、評価回数をできるだけ削減したい。

---

## アルゴリズムの全体フロー

1. 初期サンプル取得（空間全体のざっくり探索）。
2. 良さそうな点（エリート点）に基づいてクラスタ（局所リージョン）を構成。
3. 各クラスタごとに局所アンサンブルサロゲートを構築。
4. サロゲートの平均・分散から獲得関数を定義し、次に評価する候補点を選択。
5. 実際に \( f(x) \) を評価。
6. 結果に基づき、各クラスタのトラストリージョン半径を更新。
7. 評価予算に達するまで 2–6 を繰り返す。

---

## 詳細ステップ

### 1. 初期サンプル

- 評価回数： \( n_{	ext{init}} \)（例： \( 10d \) など）
- サンプリング方式：
  - ラテン超方格
  - Sobol シーケンス
  - 一様乱数  
  などのいずれか。

得られた点 \( x_i \) に対し \( y_i = f(x_i) \) を計算し、データ集合

\[
\mathcal{D} = \{(x_i, y_i)\}_{i=1}^{n_{	ext{init}}}
\]

を構成する。

### 2. クラスタ（局所リージョン）の生成

1. データ集合 \( \mathcal{D} \) を、目的値 \( y_i \) が小さい順（良い順）にソート。
2. 上位 \( n_{	ext{elite}} \) 個のエリート点を抽出。
3. そのエリート点集合に対して \( K \) クラスタのクラスタリング（例：k-means）を適用。
4. 各クラスタ \( C_k \) について：
   - 重心 \( c_k \) を計算。
   - 初期トラストリージョン半径 \( r_k \) を設定。  
     例：探索空間 \( \Omega \) の対角長の 10% など。

これにより、複数の「有望な局所領域」が確立される。

### 3. 局所アンサンブルサロゲートの構築

各クラスタ \( C_k \) に対して：

1. **近傍データの抽出**  
   クラスタ中心 \( c_k \) から距離 \( r_k \) 以内のデータ点で部分集合を作る：

   \[
   \mathcal{D}_k = \{(x_i, y_i) \in \mathcal{D} : \|x_i - c_k\| \le r_k\}
   \]

2. **アンサンブルサイズ \( M \)** を決める（例：5〜10）。

3. \( m = 1, \dots, M \) に対し、それぞれ軽量モデルを学習：

   - ランダムサブサンプリング：  
     \( \mathcal{D}_k \) から一部の点のみを用いる。
   - ランダム特徴射影：  
     \[
     z = W_m x + b_m
     \]
     などのランダム特徴に写像してから線形回帰（リッジ回帰）を学習する。
   - あるいはランダムフォレスト等の軽量決定木モデルを使うことも可能。

この操作によって、クラスタ \( k \) に対して \( M \) 個のモデル \( \hat f_{k,m}(x) \) が得られる。

**予測時**（任意の点 \( x \) に対して）：

- 平均予測：

  \[
  \mu_k(x) = rac{1}{M} \sum_{m=1}^M \hat f_{k,m}(x)
  \]

- 分散（不確実性）：

  \[
  \sigma_k^2(x) =
    rac{1}{M-1} \sum_{m=1}^M igl(\hat f_{k,m}(x) - \mu_k(x)igr)^2
  \]

### 4. 候補点選択（局所獲得関数）

クラスタ \( k \) ごとに、トラストリージョン内で獲得関数を最大化する点を探索する。

例として、Upper Confidence Bound（UCB）型の獲得関数：

\[
  a_k(x) = -\mu_k(x) + \kappa \sigma_k(x),
  \quad 	ext{s.t. } \|x - c_k\| \le r_k
\]

- \(-\mu_k(x)\)：平均予測が小さい（良い）点を好む項。
- \( \kappa \sigma_k(x) \)：不確実性が大きい点も探索する項。

**最適化方法**（サロゲート上の最適化のため、そこまで高精度でなくてよい）：

1. トラストリージョン内にランダムあるいは Sobol シーケンスで
   数十〜数百点の候補点 \( x^{(j)} \) を生成。
2. 各点で \( a_k(x^{(j)}) \) を計算。
3. \( a_k \) が最大となる点を候補点 \( x_k^{	ext{next}} \) とする。

これをクラスタ \( k = 1, \dots, K \) で行うことで、

\[
\{x_1^{	ext{next}}, \dots, x_K^{	ext{next}}\}
\]

という複数の候補点が得られる。

### 5. 実際の関数評価

- 評価コストに余裕があれば、すべてのクラスタから1点ずつ評価：

  \[
  y_k^{	ext{next}} = f(x_k^{	ext{next}})
  \]

- 評価コストが特に高く、1点しか評価できない場合は、
  複数候補点のうち「期待改善量」や \( \mu, \sigma \) を参考に
  1点に絞るなどの戦略を取る。

評価した点はデータ集合に追加：

\[
\mathcal{D} \leftarrow \mathcal{D} \cup \{(x_k^{	ext{next}}, y_k^{	ext{next}})\}
\]

### 6. クラスタとトラストリージョンの更新

各クラスタ \( k \) について、

- 新しい点 \( x_k^{	ext{next}} \) の評価値 \( y_k^{	ext{next}} \) が、
  クラスタ内のベスト値を更新した場合 → **成功**
- そうでない場合 → **失敗**

とみなす。

**成功時：**

トラストリージョン半径を拡大（上限付き）：

\[
r_k \leftarrow \min(\gamma_{	ext{inc}} r_k, r_{\max})
\]

例： \( \gamma_{	ext{inc}} = 1.2 \)。

**失敗時：**

トラストリージョン半径を縮小（下限付き）：

\[
r_k \leftarrow \max(\gamma_{	ext{dec}} r_k, r_{\min})
\]

例： \( \gamma_{	ext{dec}} = 0.5 \)。

**クラスタの再編成：**

一定ステップごと（例：10 外ループごと）に、

1. データ集合全体から上位 \( n_{	ext{elite}} \) を再び抽出。
2. それをもとに再度 k-means などでクラスタリング。

これにより、

- 「既に行き止まりになった谷」を捨てる。
- 新しく見つかった有望な領域にクラスタを割り当て直す。

---

## 擬似コード（簡略）

```pseudo
Input: domain Ω, budget B, dim d
Hyperparams:
  n_init, n_elite, K, M, κ
  r_min, r_max, γ_inc, γ_dec

# 1. 初期サンプル
D = {}
for i in 1..n_init:
    x_i = SampleUniform(Ω)
    y_i = f(x_i)
    D.add((x_i, y_i))

evals = n_init

# 2. 最適化ループ
while evals < B:

    elite = TopNByY(D, n_elite)      # 小さい y 順
    clusters = KMeans(elite.x, K)    # 得られるクラスタ C_k

    for each cluster k:
        c_k = ClusterCenter(clusters[k])
        r_k = InitOrPreviousRadius(k)

    next_points = []

    for each cluster k:

        D_k = { (x,y) in D | ||x - c_k|| <= r_k }
        if |D_k| < d+1:
            # データ不足ならランダム探索
            x_new = SampleBall(c_k, r_k)
            next_points.add((k, x_new))
            continue

        # 局所アンサンブルサロゲート学習
        models = []
        for m in 1..M:
            D_sub = RandomSubset(D_k)
            model = FitRandomFeatureRidge(D_sub)
            models.add(model)

        # 候補点探索
        best_x = None
        best_a = -inf
        for j in 1..J:   # J は候補サンプル数
            x_cand = SampleBall(c_k, r_k)
            mu, sigma = EnsemblePredict(models, x_cand)
            a = -mu + κ * sigma
            if a > best_a:
                best_a = a
                best_x = x_cand

        next_points.add((k, best_x))

    # 関数評価 & トラストリージョン更新
    for (k, x_new) in next_points:
        if evals >= B: break
        y_new = f(x_new)
        D.add((x_new, y_new))
        evals += 1

        if y_new < BestInCluster(D, k):
            r_k = min(γ_inc * r_k, r_max)
        else:
            r_k = max(γ_dec * r_k, r_min)

# 出力: D の中の最良点
x_best, y_best = argmin_y(D)
return x_best, y_best
```

---

## 計算量と実用性

### 計算量（概略）

- サロゲート学習：
  - 各クラスタでサブセットサイズを \( n_k \)、特徴数を \( p \) としたとき、
    1 モデルあたり \( O(n_k p^2) \)（リッジ回帰の場合）程度。
  - これを \( M \) 個、クラスタ数 \( K \) 個で学習する。

- 獲得関数の最適化：
  - 各クラスタで候補数 \( J \) のランダムサンプリングを行い、
    各候補点でアンサンブル予測を行う程度の計算。

**関数評価が非常に高価な設定**（シミュレーションや物理実験など）では、  
これらの学習コストは十分に受容可能な範囲と見なせる。

### 実用上のメリット

- ガウス過程ベイズ最適化（GP-BO）に比べて：
  - 線形回帰やランダム特徴に基づくため、実装が比較的シンプル。
  - 高次元へのスケール性がやや良い（ただし無制限ではない）。
- CMA-ES などの進化戦略に比べて：
  - モデルベースで「不確実性」を明示的に扱える。
  - 複数クラスタによるマルチモーダル探索が自然に実現される。

---

## 拡張アイデア

実装後に改良を加える際の方向性：

1. **整数・カテゴリ変数への対応**  
   - ワンホット化、あるいはカテゴリー embedding を導入し、
     ランダム特徴や決定木モデルに取り込む。

2. **ノイズの取り扱い**  
   - サロゲートの不確実性が高い点に対してのみ再評価を行い、
     推定分散を減らす戦略を導入。

3. **並列評価**  
   - 各クラスタから複数候補点を選び、GPU クラスタや実験設備で並列に評価。

4. **ハイパーパラメータ自動調整**  
   - \( \kappa \)、\( r_{\min}, r_{\max} \)、アンサンブルサイズ \( M \)、
     候補数 \( J \) などをメタ最適化（ベイズ最適化など）でチューニング。

---

## まとめ

LENS-BO は、

- 「複数の局所リージョン」を並行して維持しつつ、
- 各リージョン内で「アンサンブルサロゲート」を構築し、
- 平均・分散に基づく獲得関数で候補点を選ぶ

という構造をもつブラックボックス最適化アルゴリズム案である。

ガウス過程ベイズ最適化と CMA-ES の中間のような位置づけで、

- GP ほど重くなく、
- 進化戦略よりも「不確実性」を活用しやすい

という実用上のメリットが期待できる。

実装する際は、NumPy / PyTorch / scikit-learn などを用いて、
局所サロゲート部分（ランダム特徴 + リッジ回帰 or ランダムフォレスト）
から試すと良い。
