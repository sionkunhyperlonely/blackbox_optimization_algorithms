# BaRT-ES：Bandit-guided Region-wise Trust Evolution Strategy  
ブラックボックス最適化アルゴリズム設計メモ

---

## 1. 概要

本ドキュメントでは、連続値の実関数ブラックボックス最適化のための新しいアルゴリズム  
**BaRT-ES（Bandit-guided Region-wise Trust Evolution Strategy）** を設計する。

対象とする問題は、以下のようなセッティングを想定する。

- 評価コストが高い（シミュレーション、実験、学習など）
- 勾配や解析的な構造情報は利用できない
- 多峰性（局所解が多数存在）
- 並列評価（バッチ評価）が可能

BaRT-ES は直感的には次のようなアイデアを組み合わせた階層型アルゴリズムである。

1. 探索空間を **複数の局所領域（region / trust region）** に分割
2. 各領域ごとに  
   - **ローカルサロゲートモデル（surrogate model）** を構築  
   - **局所進化戦略（ES, CMA-ES 風）** による候補生成を行う
3. どの領域をどれだけ深掘りするかを、  
   **マルチアームドバンディット（UCB 系）** で決定
4. データが溜まった領域は
   - **分割（split）** して細かく探索
   - 似た・弱い領域は **統合（merge）** して計算量を抑制

すなわち、

> 「ES ベースのローカルサンプリング + ローカルサロゲート +  
>  バンディットによる領域選択 + 自動分割／統合」

を一つの汎用フレームワークにまとめたブラックボックス最適化アルゴリズムである。

---

## 2. 問題設定

- **目的関数**  
  \( f: \mathcal{X} \to \mathbb{R} \)  
  - 微分不可でよい
  - ノイズありでもよい（確率的出力でも可）

- **探索空間**  
  \( \mathcal{X} = [l_1, u_1] \times \cdots \times [l_d, u_d] \subset \mathbb{R}^d \)

- **制約**  
  - 評価回数の上限：\( T \)
  - 1ステップあたりの並列評価数（バッチサイズ）：\( B \)

- **目的**  
  - 合計評価回数 \( T \) の範囲内で、
    \( f(x) \) を最小化するような \( x \in \mathcal{X} \) を見つける。

---

## 3. アルゴリズム概要：BaRT-ES

### 3.1 内部状態

BaRT-ES は内部に以下を保持する。

- **領域集合** \( \{R_k\}_{k=1}^K \)
  - 領域中心 \( c_k \in \mathbb{R}^d \)
  - 領域サイズ（半径、あるいは軸方向ごとの幅）\( r_k \)

- **各領域のローカル状態**
  - **ローカルデータ**：  
    \( D_k = \{(x_i, y_i) \in D \mid x_i \in R_k\} \)
  - **サロゲートモデル** \( \hat{f}_k(x) \)  
    例：  
    - 低次元：Gaussian Process（GP）  
    - 中〜高次元：Random Forest / XGBoost / RBF Network など
  - **ローカル ES パラメータ**
    - 平均ベクトル：\( m_k \)
    - 共分散行列：\( C_k \)
    - ステップサイズ：\( \sigma_k \)
  - **バンディット統計**
    - 訪問回数：\( n_k \)
    - 報酬推定値：\( q_k \)（その領域がどれだけ改善を生んでいるかの指標）

- **グローバル情報**
  - 全観測データ集合：\( D = \{(x_i, y_i)\} \)
  - グローバルベスト：\( x_{\text{best}}, f_{\text{best}} \)

---

### 3.2 初期化

1. **初期サンプリング**
   - LHS（ラテン超方格）や一様乱数で \( N_0 \) 点 \( x_1, \dots, x_{N_0} \) をサンプリング。
   - 各点で \( y_i = f(x_i) \) を評価し、\( D \) に格納。

2. **初期クラスタリング → 領域生成**
   - 入力ベクトル \( \{x_i\}_{i=1}^{N_0} \) に対し K-means などで  
     \( K_{\text{init}} \) クラスタに分割。
   - 各クラスタを 1 つの領域 \( R_k \) とする。
     - 領域中心：クラスタ中心 \( c_k \)
     - 半径：クラスタ内の最大距離や分散から設定 \( r_k \)

3. **各領域のローカル状態の初期化**
   各領域 \( R_k \) について：

   - ローカルデータ：\( D_k = \{(x_i, y_i) \in D \mid x_i \in R_k\} \)
   - サロゲート：\( D_k \) を用いて \( \hat{f}_k \) を学習
   - ES 平均：\( m_k = \arg\min_{(x_i, y_i) \in D_k} y_i \)
   - 共分散：\( C_k = I_d \)（単位行列）
   - ステップサイズ：\( \sigma_k = r_k / 3 \) など
   - バンディット統計：
     - \( n_k = |D_k| \)
     - \( q_k \) は 0 または初期改善量に基づき設定

4. **グローバルベストの設定**
   - \( x_{\text{best}} = \arg\min_{i} y_i \)
   - \( f_{\text{best}} = \min_i y_i \)

---

### 3.3 メインループ

反復インデックスを \( t \) とし、評価予算 \( T \) を使い切るまで  
次を繰り返す。1 ステップで最大 \( B \) 点まで評価可能とする。

#### ステップ (1)：領域の魅力度スコアの計算

各領域 \( R_k \) について、スコア \( S_k \) を計算して、  
「どの領域を優先的に探索するか」を決定する。

1. **搾取（exploit）指標：局所改善ポテンシャル**

   - 領域 \( R_k \) 内で数点サンプルし、サロゲート \( \hat{f}_k \) を用いて、
     もっとも良さそうな候補 \( x_k^\star \) を見つける。
   - \( x_k^\star \) において、
     - 予測平均：\( \hat{\mu}_k(x_k^\star) \)
     - 予測分散：\( \hat{\sigma}_k^2(x_k^\star) \)
   - それらを用いて期待改善（EI）に類似した指標 \( EI_k \) を求める  
     （必要なら近似・簡略化してもよい）。

2. **探索（explore）指標：UCB 型の不確実性**

   - マルチアームドバンディットの UCB に基づき、
     \[
       U_k = \sqrt{\frac{2 \log t}{n_k + 1}}
     \]
     とする。訪問回数の少ない領域ほど \( U_k \) が大きくなる。

3. **総合スコアの計算**

   - 搾取と探索の両方を加味するため、正規化された指標を用いて
     \[
       S_k = \text{scale}(EI_k) + \lambda \cdot \text{scale}(U_k)
     \]
   - `scale` は平均 0・分散 1 などの正規化関数。
   - \( \lambda \in [0.1, 1] \) は探索 vs 搾取のバランスパラメータ。

#### ステップ (2)：バッチを各領域へ割り当て

バッチサイズ \( B \) をスコアに比例して各領域に割り当てる。

- 例：
  \[
    b_k
    = \max\Bigl(1, \Bigl\lfloor
      B \cdot \frac{S_k}{\sum_j S_j} \Bigr\rceil
    \Bigr)
  \]
- 最後に \( \sum_k b_k = B \) となるよう微調整する（余りをスコアの大きい領域に足す等）。

#### ステップ (3)：各領域内での候補生成（ES + サロゲート）

各領域 \( R_k \) で、割り当てられた \( b_k \) 個の評価候補点を生成する。

1. **ES による候補サンプル生成**

   - \( M_k = \rho b_k \)（\( \rho > 1 \)）個の候補を生成：
     - \( z_i \sim \mathcal{N}(0, C_k) \)
     - \( \tilde{x}_i = m_k + \sigma_k z_i \)
     - \( \tilde{x}_i \) をボックス制約 \( [l,u] \) および領域 \( R_k \) 内にプロジェクション

2. **サロゲートによるスコアリング**

   - 各候補 \( \tilde{x}_i \) に対して \( \hat{f}_k \) で予測し、
     たとえば UCB/LCB 型の獲得関数
     \[
       a(\tilde{x}_i)
       = \hat{\mu}_k(\tilde{x}_i)
         - \kappa \cdot \hat{\sigma}_k(\tilde{x}_i)
     \]
     などを計算する（最小化問題なので小さいほど良い）。

3. **上位 \( b_k \) 点の選出**

   - \( a(\tilde{x}_i) \) が小さい順に \( b_k \) 点を選び、
     それらを真の関数評価に回す。

#### ステップ (4)：真の関数評価

全領域で選ばれた候補点を集め、合計 \( B \) 点について

\[
  y = f(x)
\]

を評価する。結果は

- 全体データ集合：\( D \)
- 各ローカル集合：\( D_k \)

に追加する。

#### ステップ (5)：ES・サロゲート・バンディット統計の更新

各領域 \( R_k \) について：

1. **ES パラメータの更新**

   - 今ステップで得られた新しいサンプルを用いて、
     rank-\( \mu \) CMA-ES 風の更新則で \( m_k, C_k, \sigma_k \) を更新する。
   - 一定割合の候補が過去のベストを改善しているかどうかで
     \( \sigma_k \) を増減させる（1/5 success rule 的なアイデア）。

2. **サロゲートの更新**

   - 新しい \( D_k \) に基づき \( \hat{f}_k \) を再学習  
     （あるいはオンラインアップデート）。

3. **バンディット報酬の更新**

   - 領域 \( R_k \) 内でのベスト値の改善量を
     \[
       \Delta_k
       = \max\bigl(0,
         f_{\text{best},k}^{\text{old}} - f_{\text{best},k}^{\text{new}}
       \bigr)
     \]
     などとして定義。
   - スケーリング後の報酬 \( r_k \) を用いて、
     学習率 \( \eta \) による移動平均：
     \[
       q_k \leftarrow (1-\eta) q_k + \eta r_k
     \]
   - 訪問回数：\( n_k \leftarrow n_k + b_k \)

4. **グローバルベストの更新**

   - 新しい観測の中で最も良い値があれば
     \( x_{\text{best}}, f_{\text{best}} \) を更新。

#### ステップ (6)：領域の分割・統合（適応的パーティショニング）

一定ステップごと（例：\( K_{\text{split}} \) ステップごと）に、
領域構造を見直し、分割（Split）と統合（Merge）を行う。

##### 分割条件（Split）

領域 \( R_k \) が以下を満たすときに分割を検討：

- データ数が多い：\( |D_k| > N_{\text{split}} \)
- サロゲートの残差分散が大きい（単一モデルで表現しきれていない）
- 半径が依然として大きい、など

分割手順：

1. \( D_k \) 上で K-means（K=2）を実行し、2 つのクラスタ \( D_{k1}, D_{k2} \) を得る。
2. それぞれを新しい領域 \( R_{k1}, R_{k2} \) とする。
3. 各領域で：
   - サロゲート \( \hat{f}_{k1}, \hat{f}_{k2} \) を再学習
   - ES 平均 \( m_{k1}, m_{k2} \) をそれぞれのローカルベストに設定
   - 共分散・ステップサイズは元の値をコピーし微調整
   - バンディット統計：\( q_{k1}, q_{k2} \) は \( q_k \) を引き継ぎ、
     \( n_{k1} = |D_{k1}|, n_{k2} = |D_{k2}| \)

##### 統合条件（Merge）

2 つの領域 \( R_i, R_j \) が：

- 中心の距離が十分小さい：
  \( \|c_i - c_j\| < \alpha \min(r_i, r_j) \)
- 報酬推定値 \( q_i, q_j \) が近い
- 両方ともデータ数が少ない／改善があまり見込めない

といった条件を満たす場合、1 つの領域に統合する。

統合手順：

1. データを統合：\( D_{\text{new}} = D_i \cup D_j \)
2. 新しい中心・半径を統合クラスタから計算
3. 統合データでサロゲートを構築
4. ES パラメータは重み付き平均などで合成
5. バンディット統計 \( q_{\text{new}}, n_{\text{new}} \) を再計算または合成

これにより、

- **有望で複雑な部分**：分割されて細かく精査される
- **近接かつ重要度の低い領域**：統合されて計算資源を節約

という動的な領域管理が実現される。

---

## 4. ハイパーパラメータ設定例

実装時の一つのデフォルト例：

- 初期サンプル数：\( N_0 = 10d \)
- 初期領域数：\( K_{\text{init}} = \min(10, 2d) \)
- バッチサイズ：\( B \in \{8, 16, 32\} \)（並列数に合わせて）
- バンディット重み：\( \lambda \in [0.1, 0.5] \)
- 分割トリガ：\( N_{\text{split}} = 30\sim 50 \)
- サロゲート：
  - \( d \le 10 \)：Gaussian Process
  - \( d > 10 \)：Random Forest / XGBoost
- ES 更新：
  - まずは共分散を対角行列に制限した「CMA-lite」から始め、
    安定すればフル CMA-ES へ拡張。

---

## 5. 実用上の特徴・利点

### 5.1 ブラックボックス性

- 勾配・構造情報をまったく使わず、\( f(x) \) の評価のみで動作する。
- 実験・シミュレーション・学習パイプラインなど、内部が完全なブラックボックスの状況に向く。

### 5.2 評価コストが高い問題への適性

- サロゲートと UCB により、
  - 「改善余地が大きそう」
  - 「不確実性が大きい」
  領域が優先されるため、無駄な評価を抑えやすい。

### 5.3 多峰性・マルチモーダル構造への適応

- 複数領域 + バンディットにより、複数の局所最適候補を並列に追跡可能。
- 有望な領域は自動的に分割され、局所構造によりフィットしたサロゲート・ES を構築できる。

### 5.4 並列化のしやすさ

- 各ステップで生成するバッチ候補は領域ごとに独立に生成可能。
- 評価処理もバッチ単位でクラスタ・GPU・計算ノードに投げやすい。

### 5.5 既存手法との関係

- BaRT-ES は以下の要素を統合した枠組みとみなせる：
  - CMA-ES／進化戦略：ローカルなサンプル生成・分布更新
  - ベイズ最適化：サロゲートモデル + 獲得関数
  - TuRBO 的手法：ローカルトラストリージョンによる探索制御
  - マルチアームドバンディット：領域間の探索／搾取バランスの調整
- ただし、
  - **ローカル ES とローカルサロゲートを明示的にペアにする設計**
  - **領域選択を UCB 型バンディットで行う点**
  - **領域の分割／統合を系統的に取り入れる点**
  をひとつのアルゴリズムとしてまとめているところに特徴がある。

---

## 6. 実装のためのメモ

Python でのプロトタイプ実装を想定したメモ：

- サロゲート：
  - `sklearn.gaussian_process.GaussianProcessRegressor`  
  - `sklearn.ensemble.RandomForestRegressor` など
- クラスタリング：
  - `sklearn.cluster.KMeans`
- ES 部分：
  - まずは共分散を対角に固定した簡易 ES から始めると実装が容易。
  - 安定後、CMA-ES 系のライブラリ（`cma` など）を統合することも可能。
- 並列化：
  - Python 標準の `multiprocessing` や `joblib`、
    あるいはクラスタ基盤に合わせたジョブサブミットで評価を非同期に投げる。

---

## 7. 拡張と応用

BaRT-ES は枠組みとして拡張余地が大きい。例えば：

- **条件付きパラメータ（conditional parameters）への対応**
  - サロゲートをツリーベースにする、
  - 実行不可能領域をペナルティで処理するなど。

- **制約付き最適化**
  - 制約関数を別サロゲートで学習し、
    確率的に制約を満たす点に獲得関数を制限する。

- **多目的最適化**
  - 各領域でパレート前線を近似し、
    バンディット報酬をハイパーボリューム改善などで定義する。

- **メタ学習・ウォームスタート**
  - 過去の最適化ログから初期領域・初期サロゲートを学習し、
    新しいタスクに素早く適応する。

---

以上が、ブラックボックス実用最適化向けの新しいアルゴリズム案 **BaRT-ES** の設計である。
