# BLADE: Bandit-allocated Local Approximation for Derivative-free Exploration

本ファイルでは，連続空間のブラックボックス最適化のための新しいアルゴリズム **BLADE**  
(**B**andit-allocated **L**ocal **A**pproximation for **D**erivative-free **E**xploration) をまとめる。

---

## 1. 問題設定

- 探索領域  
  \[\mathcal{X} = [l_1, u_1] \times \dots \times [l_d, u_d] \subset \mathbb{R}^d\]

- 評価関数（ブラックボックス）  
  \[y = f(x) + \varepsilon\]  
  ここで \(\varepsilon\) は平均 0 のノイズを許容する。

- 目的  
  所定の評価回数 \(N_{\max}\) 内で
  \[\min_{x \in \mathcal{X}} f(x)\]
  の近似解を求める。

---

## 2. アルゴリズムのコンセプト概要

BLADE の特徴：

1. **複数の局所サロゲート（近似モデル）を「専門家」として保持**
2. **探索モードを多腕バンディットで切り替え**
3. **各専門家ごとにトラストリージョン（信頼領域）を自動調整**
4. **「モデル改善のためのサンプリング」と「最適値探索のためのサンプリング」を明示的に分離**

ざっくりいうと，

- CMA-ES のような局所探索性
- ベイズ最適化のようなサロゲートモデル利用
- TR法（Trust Region）の半径調整
- 多腕バンディットによるモード選択

を組み合わせたハイブリッドな手法である。

---

## 3. 内部状態

アルゴリズムが維持する主な状態は以下の 3 つ。

### 3.1 アーカイブ

これまで評価した点と値の集合：

\[\mathcal{A} = \{(x_i, y_i)\}_{i=1}^n\]

### 3.2 ローカル専門家（エキスパート）集合

\[\mathcal{E} = \{E_k\}_{k=1}^K\]

各専門家 \(E_k\) は以下を持つ：

- センター \(c_k \in \mathcal{X}\)
- 半径 \(r_k > 0\)（トラストリージョンのサイズ）
- ローカルサロゲートモデル \(m_k(x)\)
- モデル信頼度スコア \(s_k \in [0,1]\)

### 3.3 探索モード（アーム）

3 種類のアーム（探索モード）を持ち，多腕バンディットで選択する：

1. **Arm 1: ローカル搾取（Local Exploitation）**  
   信頼度が高い専門家を用いて最小値探索。
2. **Arm 2: モデル改善（Model Refinement）**  
   サロゲートの精度を上げるためのサンプリング。
3. **Arm 3: グローバル探索（Global Exploration）**  
   まだ探索が薄い領域に打ち込む。

各アーム \(a\) について

- 使用回数 \(n_a\)
- 平均改善量 \(\hat{\mu}_a\)

を記録し，UCB などの指標でアームを選ぶ。

---

## 4. ローカルサロゲートの構築

専門家 \(E_k\) のセンター \(c_k\) 周りの近傍点集合：

\[\mathcal{N}_k = \{(x_i, y_i) \in \mathcal{A} : \|x_i - c_k\| \le r_k\}\]

ローカル座標 \(z = x - c_k\) を使い，二次モデル：

\[
m_k(x) = a_k + b_k^\top z + \frac{1}{2} z^\top H_k z
\]

を ridge 回帰など（過学習防止のため）でフィットする。

### 4.1 信頼度スコア

- ホールドアウトや近傍内交差検証で予測誤差（標準化 RMSE 等）を計算
- 誤差が小さいほど信頼度 \(s_k\) を高く設定する（例：単調変換で [0,1] に収める）

これにより，信頼度が低い専門家は「まだモデルが粗い」とみなされ，主に Arm 2（モデル改善）で点が追加される。

---

## 5. 多腕バンディットによるアーム選択

イテレーション \(t\) でアーム \(a\) を使ったとき，そのステップで得られた新規評価点集合を \(S_a^t\) とする。  
前後のベスト値を

- 以前のベスト値 \(f_{\text{best}}^{t-1}\)
- 更新後のベスト値 \(f_{\text{best}}^{t}\)

とすると，アームの報酬：

\[
R_a^t = \max\left(0,\ f_{\text{best}}^{t-1} - f_{\text{best}}^{t} \right)
\]

アームごとに

- 平均報酬 \(\hat{\mu}_a\)
- 使用回数 \(n_a\)

を更新し，次のイテレーションでのアーム選択に UCB1 を用いる：

\[
\text{UCB}_a(t) = \hat{\mu}_a + \beta \sqrt{\frac{2 \log t}{n_a}}
\]

\(\beta\) は探索と搾取のバランスを調節するハイパーパラメータ。

---

## 6. アルゴリズム全体フロー

### 6.1 初期化

1. Sobol 列や一様乱数で \(n_0\) 個の点 \(x_1,\dots,x_{n_0}\) を \(\mathcal{X}\) 内にサンプリング。
2. それぞれ \(y_i = f(x_i)\) を評価してアーカイブ \(\mathcal{A}\) に格納。
3. アーカイブ中の良好な点をクラスタリングし，クラスタ中心を \(K\) 個の専門家センター \(c_k\) とする。
4. 各専門家に初期半径 \(r_k = r_{\text{init}}\) を与える。
5. 各アームの \(\hat{\mu}_a, n_a\) を小さな擬似カウントで初期化。

### 6.2 各イテレーション（または各バッチ）

以下を評価予算 \(N_{\max}\) に達するまで繰り返す。

#### Step 1: ローカルモデル更新

各専門家 \(E_k\) について：

1. 近傍点集合 \(\mathcal{N}_k\) を抽出
2. ローカル二次モデル \(m_k\) をフィット
3. 検証誤差から信頼度 \(s_k\) を更新

#### Step 2: アーム選択

イテレーション番号を \(t\) として，

1. 各アーム \(a\) について \(\text{UCB}_a(t)\) を計算
2. \(\text{UCB}_a(t)\) が最大のアーム \(a^*\) を選択

#### Step 3: アーム別サンプリング戦略

##### Arm 1: ローカル搾取（Local Exploitation）

1. 信頼度 \(s_k\) が一定閾値以上の専門家のみ候補とする。
2. 各候補専門家について，トラストリージョン内でのサロゲート最小値
   \(\min_{x \in B(c_k, r_k)} m_k(x)\) を評価し，最も小さい専門家 \(k^*\) を選ぶ。
3. 専門家 \(E_{k^*}\) のモデルに対して局所最小点
   \[x_{\text{model}}^* = \arg\min_{x \in B(c_{k^*}, r_{k^*})} m_{k^*}(x)\]
   を計算（解析的または小規模最適化）。
4. その周辺にガウス分布などで複数点をサンプリングし，サロゲート上で良好な点を選別して実評価する。

##### Arm 2: モデル改善（Model Refinement）

1. 各専門家 \(E_k\) に対して，近傍点の分布から主成分（固有方向）を抽出。
2. その固有方向に沿って
   \[x = c_k \pm \alpha r_k v_j\]
   のような設計点を追加し，曲率推定を安定させる。
3. 信頼度 \(s_k\) が低い専門家ほど，多くのサンプルを割り当てる。

##### Arm 3: グローバル探索（Global Exploration）

1. まだ点密度が低い領域を定量化するために，未探索度指標
   \[
   u(x) = \min_{(x_i, y_i) \in \mathcal{A}} \frac{\|x - x_i\|}{\text{尺度}}
   \]
   を定義。
2. Sobol 列などで候補点を多数生成し，
   - \(u(x)\) が大きく（既存点から遠く）
   - 既存サロゲートの予測値も極端に悪くない
   といった点を選択して実評価する。

#### Step 4: 評価 & バンディット更新

1. 選択されたアーム \(a^*\) の戦略で得た候補点について実際に \(f(x)\) を評価。
2. アーカイブ \(\mathcal{A}\) に追加。
3. ベスト値の改善量
   \[
   R_{a^*}^t = \max(0, f_{\text{best}}^{t-1} - f_{\text{best}}^t)
   \]
   を計算し，アーム \(a^*\) の \(\hat{\mu}_{a^*}, n_{a^*}\) を更新。

#### Step 5: トラストリージョンと専門家セットの更新

各専門家 \(E_k\) について，直近数ステップの挙動から：

- 改善が大きく信頼度 \(s_k\) も高い場合：  
  → **半径を縮小**（局所収束フェーズ）  
  \[r_k \leftarrow \gamma_{\text{shrink}} r_k \quad (\gamma_{\text{shrink}} < 1)\]

- 改善があるが \(s_k\) が中程度：  
  → 半径をほぼ維持 or わずかに調整

- 改善が少なく \(s_k\) も低い場合：  
  → **半径を拡大**して再探索を促進  
  \[r_k \leftarrow \gamma_{\text{expand}} r_k \quad (\gamma_{\text{expand}} > 1)\]

さらに，

- アーカイブ中の上位点を定期的に再クラスタリングし，
- 貢献の少ない専門家を廃止し，新しい山（良好なクラスタ）にセンターを移す

ことで，多峰性のある関数に対しても柔軟に対応する。

#### Step 6: 停止条件

- 評価回数が \(N_{\max}\) に到達
- 全専門家の半径 \(r_k\) が非常に小さくなり，一定期間ほとんど改善がない

などの条件で停止し，アーカイブ \(\mathcal{A}\) の中から最良の \(x\) を返す。

---

## 7. 擬似コード

```pseudo
Input: domain X, budget N_max, initial_samples n0, #experts K, batch_size B

# 初期サンプル
A = sample_sobol_or_uniform(X, n0)
evaluate f on all points in A

# 専門家初期化
E = init_experts_from_topK(A, K)

init bandit stats for arms = {Local, Refine, Global}

while evals_used < N_max:
    # 1. ローカルモデル更新
    for each expert Ek in E:
        Nk = neighbors(A, center=ck, radius=rk)
        fit quadratic model mk on Nk
        sk = compute_reliability(mk, Nk)

    # 2. アーム選択 (UCB)
    a_star = argmax_a UCB_a(t)

    # 3. アームに応じたサンプリング
    if a_star == Local:
        X_new = local_exploitation(E, B)
    elif a_star == Refine:
        X_new = model_refinement(E, B)
    else:
        X_new = global_exploration(A, E, B)

    # 4. 評価 & バンディット更新
    Y_new = [f(x) for x in X_new]
    A += (X_new, Y_new)

    improvement = max(0, best_before - best_after)
    update_bandit_stats(a_star, improvement)

    # 5. 専門家のTR更新 & 入れ替え
    update_trust_regions_and_centers(E, A)

return best_x_in(A)
```

---

## 8. ハイパーパラメータ設定の目安

- 専門家数 \(K\)： 3〜10（次元や多峰性に依存）
- 初期サンプル \(n_0\)： おおよそ \(10d\)〜\(20d\) 点
- バッチサイズ \(B\)： 並列計算リソースに応じて 4〜32 程度
- UCB の \(\beta\)： 0.5〜2 程度でチューニング
- トラストリージョン更新係数：
  - \(\gamma_{\text{shrink}} \approx 0.5\)
  - \(\gamma_{\text{expand}} \approx 1.5\)

---

## 9. 既存法との違い・位置づけ

- **多腕バンディットによる「探索モード」自動切り替え**  
  局所探索・モデル改善・グローバル探索といった「モード」自体の有効性をオンラインで学習し，  
  有望なモードにリソースを多く割り当てる。

- **複数のローカル専門家＋トラストリージョン**  
  グローバルなガウス過程のように全空間を一発でモデリングするのではなく，  
  「局所二次モデルの集合」として扱うことで，次元がそこそこ高い場合や多峰性でも扱いやすい。

- **モデル改善と最小値探索の明示的分離**  
  通常のベイズ最適化では acquisition 関数の内部で「不確実性低減」と「最小値探索」が混在するが，  
  BLADE では，  
  - サロゲート精度向上（Arm 2）  
  - 最適値探索（Arm 1）  
  を別個のアームとして扱い，「どちらがどれだけ役に立ったか」を報酬として学習する。

---

## 10. 実装上のヒント（Python 想定）

- サンプリング：`scipy.stats.qmc.Sobol` など
- クラスタリング：`scikit-learn` の `KMeans`
- ローカル二次回帰：`sklearn.linear_model.Ridge`
- 多腕バンディット：UCB1 は数行で自前実装可能

本設計は，あくまで連続・ボックス制約ありの実数最適化を想定したベース版である。  
離散変数が混ざる場合や制約付き最適化，強いノイズがある場合などには，

- 専門家ごとのサロゲートを混合型（離散＋連続）にする
- ペナルティ法や可行性モデルを追加する
- ロバスト目的（期待値や分位点）を報酬として扱う

などの拡張が考えられる。
